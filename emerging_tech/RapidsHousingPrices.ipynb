{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RapidsHousingPrices.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPheysEmi9sl"
      },
      "source": [
        "# Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XF0H4EYag_2R"
      },
      "source": [
        "# Install RAPIDS\n",
        "!git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n",
        "!bash rapidsai-csp-utils/colab/rapids-colab.sh 0.19\n",
        "\n",
        "import sys, os, shutil\n",
        "\n",
        "sys.path.append('/usr/local/lib/python3.7/site-packages/')\n",
        "os.environ['NUMBAPRO_NVVM'] = '/usr/local/cuda/nvvm/lib64/libnvvm.so'\n",
        "os.environ['NUMBAPRO_LIBDEVICE'] = '/usr/local/cuda/nvvm/libdevice/'\n",
        "os.environ['CONDA_PREFIX'] = '/usr/local'\n",
        "for so in ['cudf', 'rmm', 'nccl', 'cuml', 'cugraph', 'xgboost', 'cuspatial']:\n",
        "  fn = 'lib'+so+'.so'\n",
        "  source_fn = '/usr/local/lib/'+fn\n",
        "  dest_fn = '/usr/lib/'+fn\n",
        "  if os.path.exists(source_fn):\n",
        "    print(f'Copying {source_fn} to {dest_fn}')\n",
        "    shutil.copyfile(source_fn, dest_fn)\n",
        "if not os.path.exists('/usr/lib64'):\n",
        "    os.makedirs('/usr/lib64')\n",
        "for so_file in os.listdir('/usr/local/lib'):\n",
        "  if 'libstdc' in so_file:\n",
        "    shutil.copyfile('/usr/local/lib/'+so_file, '/usr/lib64/'+so_file)\n",
        "    shutil.copyfile('/usr/local/lib/'+so_file, '/usr/lib/x86_64-linux-gnu/'+so_file)\n",
        "\n",
        "!pip install -U cffi\n",
        "!wget https://vcu-dapt-615.s3.amazonaws.com/properties_2016.csv.zip\n",
        "!unzip properties_2016.csv.zip\n",
        "!wget https://vcu-dapt-615.s3.amazonaws.com/data_dict.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWOwrV0poDMa"
      },
      "source": [
        "# Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYtzLuDllOem"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDnLic_jhBN_"
      },
      "source": [
        "import cudf\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNqnhLDGlf0s"
      },
      "source": [
        "Before we load the data, let's check our GPU usage memory:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_98S9x0m2rJ"
      },
      "source": [
        "Let's first load the data into local memory using `pandas`, and check the starting gpu memory usage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqcAqbO4hVqZ"
      },
      "source": [
        "%%time\n",
        "pd_data = pd.read_csv('properties_2016.csv', low_memory=False)\n",
        "pd_data = pd_data.drop([\n",
        "                        'propertycountylandusecode',\n",
        "                        'propertyzoningdesc',\n",
        "                        'taxdelinquencyflag', \n",
        "                        'taxamount', \n",
        "                        'structuretaxvaluedollarcnt', \n",
        "                        'landtaxvaluedollarcnt'\n",
        "                        ], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tV8v1W52lxta"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmTM96k0nPgA"
      },
      "source": [
        "Now let's put the data into gpu memory by creading a `cuDF` `DataFrame`, and then check our gpu memory utilization:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOAEQx1YhZ_L"
      },
      "source": [
        "data = cudf.from_pandas(pd_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWGWX7ewha1K"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GemEHugQngxj"
      },
      "source": [
        "**Question 1**: How much memory (in MiB) does the `DataFrame` consume?\n",
        "\n",
        "[PLEASE TYPE YOUR ANSWER HERE]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CiXO9IFoIiY"
      },
      "source": [
        "## Data Inspection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dy6DKKUboMyr"
      },
      "source": [
        "Now that we have our data loaded, let's see if we can answer some quick questions about the data. We'll also try to take a look at the performance differences between `pandas` and `cuDF` `DataFrames`. \n",
        "\n",
        "Let's start with some simple some simple details about the data. Answer the following questions below. Note that the column descriptions can be found in the file `data_dict.csv`, and loaded with `lookup = pd.read_csv('data_dict.csv')`\n",
        "\n",
        "**Question 2**: What's the mean value of the properties (from tax assessment) in dollars for the data set? Are there any assessed values that stand out to you as unusual?\n",
        "\n",
        "**Question 3**: How many columns are in `DataFrame`? Do any of the columns have `Null` values? Should we just remove columns/rows with nulls in them?\n",
        "\n",
        "**Question 4**: How many different zip codes are the properties located in? How many different cities? (look at the `regionid*` fields for this, e.g. `regionidcity`)\n",
        "\n",
        "**Question 5**: Which `regionidcity` has the most proprties, and what is the min, mean, median, max values for properties there?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwBMuNawoLyS"
      },
      "source": [
        "# Question 2 code here\n",
        "data.taxvaluedollarcnt.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XR9eA8Fzrrss"
      },
      "source": [
        "# Question 3 code here\n",
        "print(data.shape)\n",
        "print(data.isnull().any())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4AK0l5MkhIc"
      },
      "source": [
        "# Question 4 code here\n",
        "print(data.regionidzip.nunique())\n",
        "print(data.regionidcity.nunique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8mX_1-pm7Em"
      },
      "source": [
        "# Question 5 code here\n",
        "data.groupby('regionidcity')['parcelid'].count().sort_values(ascending=False).head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQ352Dk10O5C"
      },
      "source": [
        "data[data['regionidcity'] == 12447.0]['taxvaluedollarcnt'].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tdwr6OJenE8M"
      },
      "source": [
        "We saw above that we have some `Null` in the data. We'd like to fill in these values with the mean value for each column. \n",
        "\n",
        "**Question 6**: Write a `for` loop to loop through each of the columns in the `DataFrame`, compute the mean of that column with the `mean()` `Series` method, then use the `fillna()` `Series` method to fill `Null` values in that column with the mean value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I02pcrROm9N0"
      },
      "source": [
        "%%time\n",
        "for column in data.columns:\n",
        "\n",
        "    # Check to see if the column has any null values\n",
        "    if not data[column].isnull().any():\n",
        "      continue\n",
        "    # Compute the mean for the column\n",
        "    # Question 6 code here\n",
        "    mean = data[column].mean()\n",
        "\n",
        "    # use `fillna` to fill the null values in the column with the mean\n",
        "    # Question 6 code here\n",
        "    data[column] = data[column].fillna(mean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdRnXxw-xhfS"
      },
      "source": [
        "**Question 7**: Verify that none of the columns have any nulls in them.\n",
        "\n",
        "*Hint: try `.isnull()` and `.any()` methods*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lw31hNNojRV"
      },
      "source": [
        "# Question 7 code here\n",
        "data.isnull().any()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XjWgjufxXtu"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NM54IkHunqFE"
      },
      "source": [
        "from cuml.ensemble import RandomForestRegressor\n",
        "from cuml.preprocessing.model_selection import train_test_split\n",
        "from cuml.metrics import mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "# Convert the data types so they play well with cuML\n",
        "data = data.astype(np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHLA9fMvxdHq"
      },
      "source": [
        "**Question 8**: Create a train/test split (with say 80% of the data in the training set), with the `taxvaluedollaramount` as the target variable. \n",
        "\n",
        "Name the outputs `X_train, X_test, y_train, y_test`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "or0efyUBsDEv"
      },
      "source": [
        "# Question 8 code here\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, 'taxvaluedollarcnt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQQ5HFJiySx9"
      },
      "source": [
        "**Question 9**: Create a `RandomForestRegressor` object and fit your training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byskFliLtm6N"
      },
      "source": [
        "# Question 9 code here\n",
        "clf = RandomForestRegressor(n_estimators=40,\n",
        "                   max_depth=16,\n",
        "                   max_features=1.0)\n",
        "\n",
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrvgL1BSygV3"
      },
      "source": [
        "**Question 10**: Make predictions on the test data and calculate the mean absolute error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJim2azftyH1"
      },
      "source": [
        "# Question 10 code here\n",
        "y_pred = clf.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(mae)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHGTQhgwwqVT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}